{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9ca5828",
   "metadata": {},
   "source": [
    "# Learn basics in NLP with TensorFlow "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8e7aa5",
   "metadata": {},
   "source": [
    "I'm gonna follow this github tutorial.\n",
    "\n",
    "https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/08_introduction_to_nlp_in_tensorflow.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2246e838",
   "metadata": {},
   "source": [
    "Get dataset from kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45e53004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "151d38b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./dataaset/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a3ca68d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb9fd29",
   "metadata": {},
   "source": [
    "Split data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ced96de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_sentences, val_sentences, train_lables, val_lables = train_test_split(\n",
    "    train_data[\"text\"].to_numpy(),\n",
    "    train_data[\"target\"].to_numpy(),\n",
    "    test_size=0.1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71583705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Guaranteed been bitten by some mutant mosquito my ankle has blown up. Little cunts',\n",
       "       '@RJG0789 idk....I feel like his movies have done more harm than good. They make us look sterotypical annddd colorism is prevalent sort of',\n",
       "       'I liked a @YouTube video http://t.co/43sXG9Z6xh TREMOR IS NO JOKE!! [TREMOR DLC] [FATALITIES/X-RAY]',\n",
       "       ...,\n",
       "       \"wo Pic of 16yr old PKK suicide bomber who detonated bomb in Turkey Army trench released http://t.co/5v29w19tFX /'/'//\",\n",
       "       'I feel like death',\n",
       "       'Do you have a plan? Emergency Preparedness for #Families of\\nChildren with Special Needs  http://t.co/RdOVqaUAx5  #autism #specialneeds'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b2b5db",
   "metadata": {},
   "source": [
    "# Converting text into numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329eda15",
   "metadata": {},
   "source": [
    "Create words to vector function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8db3737e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f4054ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-04 16:25:13.667310: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-01-04 16:25:13.667336: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-01-04 16:25:13.667577: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "text2vec = TextVectorization(\n",
    "    max_tokens=10000, standardize='lower_and_strip_punctuation',\n",
    "    split='whitespace', ngrams=None, output_mode='int',\n",
    "    output_sequence_length=15, pad_to_max_tokens=False, vocabulary=None,\n",
    "    idf_weights=None, sparse=False, ragged=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c471c2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text2vec.adapt(train_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effdbba5",
   "metadata": {},
   "source": [
    "See how the words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "762f78f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
       "array([[ 75,   9,   3, 207,   4,  13, 760,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]])>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sentence = \"There is a flood in my street!\"\n",
    "text2vec([sample_sentence])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8531229f",
   "metadata": {},
   "source": [
    "Get first words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43855ba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 'the', 'a', 'in']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2vec.get_vocabulary()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae158be6",
   "metadata": {},
   "source": [
    "Get the words from 100 to 105th."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5fb4d7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['man', 'first', 'fires', 'cant', 'bomb']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2vec.get_vocabulary()[100:105]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2690c48a",
   "metadata": {},
   "source": [
    "# Creating Embedding layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca9743e",
   "metadata": {},
   "source": [
    "We are going to use TnsorFlow's embedding layers.\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a94a5eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.embeddings.Embedding at 0x7f5fe43a8f10>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "embedding = layers.Embedding(input_dim = 10000, # set imput shape\n",
    "                             output_dim = 128, # output shape\n",
    "                             input_length = 10000 # how long is each input \n",
    "                            )\n",
    "\n",
    "embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082231d8",
   "metadata": {},
   "source": [
    "Get a random sentence from the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2839bf7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      " Exploration Takes Seismic Shift in #Gabon to #Somalia\n",
      "http://t.co/Ltf6jL5keU http://t.co/Zlq8tHcTkW        \n",
      "\n",
      "Embedded version:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
       "array([[[-0.00584246, -0.00486549, -0.03438734, ...,  0.01744742,\n",
       "         -0.01539519,  0.04480382],\n",
       "        [-0.02566576, -0.01726035,  0.03642262, ...,  0.03788001,\n",
       "          0.02513185,  0.03414276],\n",
       "        [ 0.02440382,  0.02525632, -0.01863666, ...,  0.00854806,\n",
       "         -0.00353139,  0.04812253],\n",
       "        ...,\n",
       "        [-0.01673266,  0.01151526,  0.00124147, ...,  0.04875894,\n",
       "         -0.04456549,  0.04744624],\n",
       "        [-0.01673266,  0.01151526,  0.00124147, ...,  0.04875894,\n",
       "         -0.04456549,  0.04744624],\n",
       "        [-0.01673266,  0.01151526,  0.00124147, ...,  0.04875894,\n",
       "         -0.04456549,  0.04744624]]], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random_sentence = random.choice(train_sentences)\n",
    "\n",
    "print(f\"Original text:\\n {random_sentence}\\\n",
    "        \\n\\nEmbedded version:\")\n",
    "\n",
    "# Embed the random sentence (turn it into dense vectors of fixed size)\n",
    "sample_embed = embedding(text2vec([random_sentence]))\n",
    "sample_embed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c6b3c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
       " array([-0.00584246, -0.00486549, -0.03438734,  0.00473927,  0.03942709,\n",
       "        -0.00914267,  0.04823155,  0.02335917,  0.00289087, -0.0079584 ,\n",
       "         0.04030385, -0.02551092,  0.01181896,  0.02185899,  0.00164554,\n",
       "        -0.02360288, -0.00598522,  0.00817355, -0.01286701, -0.01950574,\n",
       "         0.02077207, -0.01325671,  0.03551588, -0.04193858, -0.00425833,\n",
       "         0.00488   ,  0.00186374,  0.04490009,  0.04443793, -0.00309221,\n",
       "         0.00743573, -0.02974598, -0.04953986, -0.04644821, -0.03849795,\n",
       "        -0.04130647,  0.03584014, -0.04506174, -0.02111856,  0.02653432,\n",
       "         0.03120626,  0.0348633 , -0.04617438,  0.03508409, -0.00868416,\n",
       "        -0.00882361, -0.00256375, -0.04937835, -0.045761  , -0.00064474,\n",
       "         0.04234774, -0.03597004,  0.02966757,  0.04181362,  0.01648979,\n",
       "         0.03530759,  0.00140101, -0.02576051,  0.03456293, -0.0436573 ,\n",
       "        -0.03178125,  0.00496196,  0.00561043,  0.02661629, -0.00091805,\n",
       "         0.02634796,  0.00078298,  0.03753291,  0.04511293,  0.04198327,\n",
       "        -0.00142877, -0.04643539,  0.03592381, -0.00181923, -0.02844046,\n",
       "        -0.01393182,  0.03033569,  0.00828602,  0.00038308, -0.04839807,\n",
       "        -0.00119854,  0.01355514,  0.02978444, -0.02232691, -0.04620397,\n",
       "         0.02046331,  0.04637481,  0.01909849, -0.03234725, -0.01456929,\n",
       "         0.02419237,  0.04752168,  0.03869523, -0.01765103, -0.00989957,\n",
       "        -0.02773279,  0.02231023, -0.02289522, -0.02453462,  0.00128164,\n",
       "         0.02702837, -0.02890844,  0.02959004, -0.02637562, -0.02125822,\n",
       "         0.00561684, -0.02986833,  0.0157324 ,  0.04429447, -0.01391565,\n",
       "         0.00665895, -0.02613416, -0.03784662,  0.03119493,  0.00329571,\n",
       "         0.0363369 , -0.01271474,  0.04477255, -0.0236321 ,  0.02671759,\n",
       "        -0.04974374, -0.03024653,  0.02997584, -0.01587962, -0.03486402,\n",
       "         0.01744742, -0.01539519,  0.04480382], dtype=float32)>,\n",
       " TensorShape([128]),\n",
       " 'Exploration Takes Seismic Shift in #Gabon to #Somalia\\nhttp://t.co/Ltf6jL5keU http://t.co/Zlq8tHcTkW')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_embed[0][0], sample_embed[0][0].shape, random_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06be48a",
   "metadata": {},
   "source": [
    "# Modelling a text dataset with running a series of experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b331c632",
   "metadata": {},
   "source": [
    "There are some Model to learn text:\n",
    "\n",
    "0, Naive Bayes with TF-IDF encoder (baseline)\n",
    "\n",
    "1, Feed-forward neural network (dence model)\n",
    "\n",
    "2, LSTM (RNN)\n",
    "\n",
    "3, GRU (RNN)\n",
    "\n",
    "4, Bidirectional-LSTM (RNN)\n",
    "\n",
    "5, 1D Convolutional Neural Network\n",
    "\n",
    "6, TensorFlow Hub Pretrained Feature Extractor\n",
    "\n",
    "7, TensorFlow Hub Pretrained Feature Extractor (10% of data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3ceadf",
   "metadata": {},
   "source": [
    "How are we going to approach all of these?\n",
    "\n",
    "Use the standard steps in modeling with tensorflow:\n",
    "\n",
    "* Create a model\n",
    "* Build a model\n",
    "* Fit a model\n",
    "* Evaluate our model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80f8e51",
   "metadata": {},
   "source": [
    "# Create Tensorflow Pretrained model 10% of data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791506b2",
   "metadata": {},
   "source": [
    "Use only 10% of data to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a439aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab6a8103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "sentence_encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
    "                                       input_shape=[],\n",
    "                                       dtype=tf.string,\n",
    "                                       trainable=False,\n",
    "                                       name=\"USE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "574f20aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model useing the Sequence \n",
    "model_6 = tf.keras.Sequential([\n",
    "    sentence_encoder_layer,\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "], name=\"model_6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d1058c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensorboard callback ( need to a new one for each model)\n",
    "from helper_function import create_tensorboard_callback\n",
    "\n",
    "# Create a directory to save TensorBoard logs\n",
    "SAVE_DIR = \"model_logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "338146a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                                   text  target\n",
       " 4955  DFR EP016 Monthly Meltdown - On Dnbheaven 2015...       0\n",
       " 584   FedEx no longer to transport bioterror germs i...       0\n",
       " 7411  Gunmen kill four in El Salvador bus attack: Su...       1\n",
       " 5950  @camilacabello97 Internally and externally scr...       1\n",
       " 5541  Radiation emergency #preparedness starts with ...       1,\n",
       " 761)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_shuffled = train_data.sample(frac=1, random_state=42)\n",
    "train_10_percent = train_df_shuffled[[\"text\", \"target\"]].sample(frac=0.1, random_state=42)\n",
    "train_10_percent.head(), len(train_10_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "be3c45a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(761, 761)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences_10_percent = train_10_percent[\"text\"].to_list()\n",
    "train_lables_10_percent = train_10_percent[\"target\"].to_list()\n",
    "\n",
    "len(train_sentences_10_percent), len(train_lables_10_percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc392d16",
   "metadata": {},
   "source": [
    "Check the number of targets in our subset of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "189157c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    413\n",
       "1    348\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_10_percent[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ada6314f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4342\n",
       "1    3271\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_shuffled[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0b38b0",
   "metadata": {},
   "source": [
    "Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c9e27cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model_7 = tf.keras.models.clone_model(model_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "886184f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " USE (KerasLayer)            (None, 512)               256797824 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                32832     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256,830,721\n",
      "Trainable params: 32,897\n",
      "Non-trainable params: 256,797,824\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_7.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fab837a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_7.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "32a136dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_7_pretrained_10_percent/20220104-164744\n",
      "Epoch 1/5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.5984 - accuracy: 0.7937 - val_loss: 0.5691 - val_accuracy: 0.7769\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.5212 - accuracy: 0.7898 - val_loss: 0.5117 - val_accuracy: 0.7782\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.4649 - accuracy: 0.8003 - val_loss: 0.4801 - val_accuracy: 0.7927\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.4290 - accuracy: 0.8095 - val_loss: 0.4644 - val_accuracy: 0.7953\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.4041 - accuracy: 0.8265 - val_loss: 0.4549 - val_accuracy: 0.8031\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5f00301700>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_7.fit(x=train_sentences_10_percent,\n",
    "            y=train_lables_10_percent,\n",
    "            epochs=5,\n",
    "            validation_data=(val_sentences, val_lables),\n",
    "            callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
    "                                                 \"model_7_pretrained_10_percent\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "199605cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.33813885],\n",
       "       [0.0710935 ],\n",
       "       [0.45362866],\n",
       "       [0.30733424],\n",
       "       [0.22581276],\n",
       "       [0.10957441],\n",
       "       [0.46320567],\n",
       "       [0.0774343 ],\n",
       "       [0.90216565],\n",
       "       [0.12078884]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions \n",
    "model_7_pred_probs = model_7.predict(val_sentences)\n",
    "model_7_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2e44560d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_7_preds = tf.squeeze(tf.round(model_7_pred_probs))\n",
    "model_7_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "08019dc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 80.31496062992126,\n",
       " 'prediction': 0.8027449132960943,\n",
       " 'recall': 0.8031496062992126,\n",
       " 'f1': 0.8022638996116164}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate model 7\n",
    "from Evaluation import caluculate_results\n",
    "model_7_results = caluculate_results(y_true=val_lables,\n",
    "                                    y_pre=model_7_preds)\n",
    "model_7_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
