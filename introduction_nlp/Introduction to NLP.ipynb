{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9ca5828",
   "metadata": {},
   "source": [
    "# Learn basics in NLP with TensorFlow "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2246e838",
   "metadata": {},
   "source": [
    "Get dataset from kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45e53004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "151d38b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./dataaset/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a3ca68d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb9fd29",
   "metadata": {},
   "source": [
    "Split data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ced96de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_sentences, val_sentences, train_lables, val_lables = train_test_split(\n",
    "    train_data[\"text\"].to_numpy(),\n",
    "    train_data[\"target\"].to_numpy(),\n",
    "    test_size=0.1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71583705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"@DavidCovucci We can't because a sinkhole swallowed every taco place in the neighborhood\",\n",
       "       \"@MarioMaraczi I'm watching it right now.  He freaked out after the 1st.  First fight where he didn't demolish the guy\",\n",
       "       \"1 of those days when ya don't realize till already in transit that a train DERAILED at the Metro St closest to work?? https://t.co/QYX5ThkRbH\",\n",
       "       ...,\n",
       "       '???? #Krefeld: the incident happened in a chemical industry park! Emergency operations underway! A building reportly collapsed! @cnnbrk @ntvde',\n",
       "       \"'The first man gets the oyster the second man gets the shell.' Andrew Carnegie\",\n",
       "       'FedEx no longer will transport bioterror germs http://t.co/qfjjDxes7G via @USATODAY'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b2b5db",
   "metadata": {},
   "source": [
    "# Converting text into numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329eda15",
   "metadata": {},
   "source": [
    "Create words to vector function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8db3737e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f4054ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "text2vec = TextVectorization(\n",
    "    max_tokens=None, standardize='lower_and_strip_punctuation',\n",
    "    split='whitespace', ngrams=None, output_mode='int',\n",
    "    output_sequence_length=None, pad_to_max_tokens=False, vocabulary=None,\n",
    "    idf_weights=None, sparse=False, ragged=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c471c2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text2vec.adapt(train_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effdbba5",
   "metadata": {},
   "source": [
    "See how the words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "762f78f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 7), dtype=int64, numpy=array([[ 74,   9,   3, 217,   4,  13, 703]])>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sentence = \"There is a flood in my street!\"\n",
    "text2vec([sample_sentence])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8531229f",
   "metadata": {},
   "source": [
    "Get first words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "43855ba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 'the', 'a', 'in']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2vec.get_vocabulary()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae158be6",
   "metadata": {},
   "source": [
    "Get the words from 100 to 105th."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f5fb4d7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fires', 'time', 'our', 'nuclear', 'first']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2vec.get_vocabulary()[100:105]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
