{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9ca5828",
   "metadata": {},
   "source": [
    "# Learn basics in NLP with TensorFlow "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8e7aa5",
   "metadata": {},
   "source": [
    "I'm gonna follow this github tutorial.\n",
    "\n",
    "https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/08_introduction_to_nlp_in_tensorflow.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2246e838",
   "metadata": {},
   "source": [
    "Get dataset from kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45e53004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "151d38b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./dataaset/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a3ca68d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb9fd29",
   "metadata": {},
   "source": [
    "Split data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ced96de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_sentences, val_sentences, train_lables, val_lables = train_test_split(\n",
    "    train_data[\"text\"].to_numpy(),\n",
    "    train_data[\"target\"].to_numpy(),\n",
    "    test_size=0.1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71583705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['@MoorlandsChmbr Loads of stuff going on recently. See the blog at http://t.co/XVcO7sLxhW #sinkhole #piling http://t.co/jbVmGeg522',\n",
       "       'Know them recognize them......then obliterate them! \\n#gym #gymflow #gymtime #team #assassins\\x89Ã›_ https://t.co/mUHj8CbdQb',\n",
       "       'Young dancer moves about 300 youth in attendance at the GMMBC Youth Explosion this past Saturday. Inspiring! http://t.co/TMmOrvxsWz',\n",
       "       ...,\n",
       "       'Passengers evacuated &amp; lanes blocked off as power lines come down over a Gold Coast tram @9NewsGoldCoast http://t.co/zZweEezJuG',\n",
       "       'Sassy city girl country hunk stranded in Smoky Mountain snowstorm #AoMS http://t.co/HDJS9RNtJ4 #ibooklove #bookboost',\n",
       "       'I liked a @YouTube video http://t.co/jK7nPdpWRo J. Cole - Fire Squad (2014 Forest Hills Drive)'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b2b5db",
   "metadata": {},
   "source": [
    "# Converting text into numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329eda15",
   "metadata": {},
   "source": [
    "Create words to vector function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8db3737e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f4054ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "text2vec = TextVectorization(\n",
    "    max_tokens=10000, standardize='lower_and_strip_punctuation',\n",
    "    split='whitespace', ngrams=None, output_mode='int',\n",
    "    output_sequence_length=15, pad_to_max_tokens=False, vocabulary=None,\n",
    "    idf_weights=None, sparse=False, ragged=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c471c2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text2vec.adapt(train_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effdbba5",
   "metadata": {},
   "source": [
    "See how the words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "762f78f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
       "array([[ 74,   9,   3, 198,   4,  13, 771,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=int64)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sentence = \"There is a flood in my street!\"\n",
    "text2vec([sample_sentence])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8531229f",
   "metadata": {},
   "source": [
    "Get first words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43855ba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 'the', 'a', 'in']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2vec.get_vocabulary()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae158be6",
   "metadata": {},
   "source": [
    "Get the words from 100 to 105th."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5fb4d7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['see', 'bomb', 'time', 'our', 'attack']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2vec.get_vocabulary()[100:105]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2690c48a",
   "metadata": {},
   "source": [
    "# Creating Embedding layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca9743e",
   "metadata": {},
   "source": [
    "We are going to use TnsorFlow's embedding layers.\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a94a5eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.embeddings.Embedding at 0x209068a1490>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "embedding = layers.Embedding(input_dim = 10000, # set imput shape\n",
    "                             output_dim = 128, # output shape\n",
    "                             input_length = 10000 # how long is each input \n",
    "                            )\n",
    "\n",
    "embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082231d8",
   "metadata": {},
   "source": [
    "Get a random sentence from the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2839bf7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      " Fire Call: BRANT AV / DRUMMOND RD for Fire - *Structure - Single. Units: CAR 6 On Call Truck http://t.co/euDwNFyUeM        \n",
      "\n",
      "Embedded version:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
       "array([[[-0.04951564,  0.0078002 , -0.01222025, ..., -0.02327453,\n",
       "          0.0099053 ,  0.0384097 ],\n",
       "        [-0.02880297,  0.02261369, -0.01718979, ...,  0.01479206,\n",
       "          0.04564745, -0.03239497],\n",
       "        [ 0.04460982, -0.03286145, -0.03843545, ..., -0.04534746,\n",
       "         -0.02421483, -0.02914529],\n",
       "        ...,\n",
       "        [ 0.01917287,  0.04783763,  0.01503087, ...,  0.01635103,\n",
       "          0.00802214,  0.03813008],\n",
       "        [ 0.00086619,  0.00442737,  0.02149177, ...,  0.01872211,\n",
       "          0.00563936,  0.02213318],\n",
       "        [-0.02880297,  0.02261369, -0.01718979, ...,  0.01479206,\n",
       "          0.04564745, -0.03239497]]], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random_sentence = random.choice(train_sentences)\n",
    "\n",
    "print(f\"Original text:\\n {random_sentence}\\\n",
    "        \\n\\nEmbedded version:\")\n",
    "\n",
    "# Embed the random sentence (turn it into dense vectors of fixed size)\n",
    "sample_embed = embedding(text2vec([random_sentence]))\n",
    "sample_embed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c6b3c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
       " array([-0.04951564,  0.0078002 , -0.01222025,  0.04072765,  0.04100624,\n",
       "         0.03876096, -0.00401591, -0.02894153,  0.02201004,  0.03407015,\n",
       "         0.04352674, -0.02901422,  0.02552651, -0.04807413, -0.04559938,\n",
       "        -0.01662544, -0.00063174,  0.03865595,  0.00734339,  0.008965  ,\n",
       "        -0.01906165, -0.04343814, -0.03796182, -0.01543085, -0.0078395 ,\n",
       "         0.04879439,  0.03825457, -0.02467214,  0.01627273, -0.0060693 ,\n",
       "         0.0122801 , -0.01302365, -0.01803945,  0.02276829,  0.04341394,\n",
       "         0.04464534,  0.0080142 ,  0.03985028,  0.03155437,  0.03409494,\n",
       "         0.03972944, -0.02956646,  0.02102919, -0.0357822 ,  0.02046719,\n",
       "        -0.00503008, -0.00356709, -0.03743269, -0.0390722 , -0.02759565,\n",
       "         0.03918496,  0.01268556,  0.00449878,  0.0463611 , -0.04795349,\n",
       "        -0.04124595, -0.04676462,  0.00936396,  0.03810005,  0.01818502,\n",
       "         0.01095189,  0.04293311,  0.04872977,  0.01508769, -0.01856861,\n",
       "        -0.03631184, -0.0272934 ,  0.02121447,  0.00077005,  0.00266894,\n",
       "         0.02308943,  0.02629584, -0.03346583,  0.02251263,  0.00469689,\n",
       "         0.01474062,  0.00435112,  0.02071228, -0.04116995, -0.02218471,\n",
       "         0.01674939,  0.00758346, -0.00920457,  0.02479247,  0.00621246,\n",
       "        -0.02155033,  0.00191445,  0.0479775 ,  0.03116945, -0.03857689,\n",
       "        -0.00205268, -0.04212943, -0.00879486,  0.00295781,  0.04763773,\n",
       "         0.0150385 ,  0.04118791,  0.03127482, -0.02736053,  0.02890695,\n",
       "        -0.01338113,  0.04566098,  0.04413045,  0.0207409 , -0.03446497,\n",
       "        -0.00077264,  0.00984656,  0.0446378 ,  0.00151696, -0.00109021,\n",
       "         0.02483037,  0.03407269, -0.02022909, -0.00637002,  0.00033575,\n",
       "        -0.03376933, -0.00153979,  0.04260093,  0.00759362, -0.04883733,\n",
       "         0.02294688,  0.01133906, -0.02661946, -0.02813488,  0.03764092,\n",
       "        -0.02327453,  0.0099053 ,  0.0384097 ], dtype=float32)>,\n",
       " TensorShape([128]),\n",
       " 'Fire Call: BRANT AV / DRUMMOND RD for Fire - *Structure - Single. Units: CAR 6 On Call Truck http://t.co/euDwNFyUeM')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_embed[0][0], sample_embed[0][0].shape, random_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06be48a",
   "metadata": {},
   "source": [
    "# Modelling a text dataset with running a series of experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b331c632",
   "metadata": {},
   "source": [
    "There are some Model to learn text:\n",
    "\n",
    "0, Naive Bayes with TF-IDF encoder (baseline)\n",
    "\n",
    "1, Feed-forward neural network (dence model)\n",
    "\n",
    "2, LSTM (RNN)\n",
    "\n",
    "3, GRU (RNN)\n",
    "\n",
    "4, Bidirectional-LSTM (RNN)\n",
    "\n",
    "5, 1D Convolutional Neural Network\n",
    "\n",
    "6, TensorFlow Hub Pretrained Feature Extractor\n",
    "\n",
    "7, TensorFlow Hub Pretrained Feature Extractor (10% of data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3ceadf",
   "metadata": {},
   "source": [
    "How are we going to approach all of these?\n",
    "\n",
    "Use the standard steps in modeling with tensorflow:\n",
    "\n",
    "* Create a model\n",
    "* Build a model\n",
    "* Fit a model\n",
    "* Evaluate our model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6988aea5",
   "metadata": {},
   "source": [
    "# Create LSTM(RNN) layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ffeb75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "\n",
    "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
    "x = text2vec(inputs)\n",
    "x = embedding(x)\n",
    "x = layers.LSTM(64)(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_2 = tf.keras.Model(inputs, outputs, name = \"model_2_LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4e35a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2_LSTM\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization (TextVec  (None, 15)               0         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                49408     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,329,473\n",
      "Trainable params: 1,329,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a19ebc",
   "metadata": {},
   "source": [
    "Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "598e1a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.compile(loss=\"binary_crossentropy\",\n",
    "               optimizer=tf.keras.optimizers.Adam(),\n",
    "               metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ab0c27",
   "metadata": {},
   "source": [
    "Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "118dba18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensorboard callback ( need to a new one for each model)\n",
    "from helper_function import create_tensorboard_callback\n",
    "\n",
    "# Create a directory to save TensorBoard logs\n",
    "SAVE_DIR = \"model_logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "895d6a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_1_LSTM/20211229-165021\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 7s 24ms/step - loss: 0.5156 - accuracy: 0.7465 - val_loss: 0.4466 - val_accuracy: 0.7966\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 5s 21ms/step - loss: 0.3133 - accuracy: 0.8708 - val_loss: 0.4666 - val_accuracy: 0.7979\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 5s 21ms/step - loss: 0.2158 - accuracy: 0.9232 - val_loss: 0.5696 - val_accuracy: 0.7717\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 5s 21ms/step - loss: 0.1515 - accuracy: 0.9458 - val_loss: 0.6944 - val_accuracy: 0.7572\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 5s 21ms/step - loss: 0.1088 - accuracy: 0.9575 - val_loss: 0.8293 - val_accuracy: 0.7572\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_2_history = model_2.fit(x=train_sentences,\n",
    "                             y=train_lables,\n",
    "                             epochs=5,\n",
    "                             validation_data = (val_sentences, val_lables),\n",
    "                             callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
    "                                                                   experiment_name=\"model_1_LSTM\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fd9d9f39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99954623],\n",
       "       [0.00243211],\n",
       "       [0.04912975],\n",
       "       [0.0180428 ],\n",
       "       [0.375425  ],\n",
       "       [0.4732651 ],\n",
       "       [0.1736669 ],\n",
       "       [0.9829545 ],\n",
       "       [0.10995877],\n",
       "       [0.11345091]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make prediction of LSTM\n",
    "model_2_pred_prob = model_2.predict(val_sentences)\n",
    "model_2_pred_prob[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2aa8ff8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([1., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert model 2 prediction to lable format \n",
    "model_2_pred =tf.squeeze(tf.round(model_2_pred_prob))\n",
    "model_2_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2f46d695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 75.7217847769029,\n",
       " 'prediction': 0.7572982515398522,\n",
       " 'recall': 0.7572178477690289,\n",
       " 'f1': 0.7539976852065212}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Caliculate our model_2 results\n",
    "from Evaluation import caluculate_results\n",
    "\n",
    "model_2_results = caluculate_results(y_true=val_lables, \n",
    "                                   y_pre=model_2_pred)\n",
    "model_2_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
