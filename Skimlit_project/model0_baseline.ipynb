{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42d4c1f7",
   "metadata": {},
   "source": [
    "# Create baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d71da6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b38069d",
   "metadata": {},
   "source": [
    "Read csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8aed2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"dataset/csv/train.csv\")\n",
    "test_data = pd.read_csv(\"dataset/csv/test.csv\")\n",
    "val_data = pd.read_csv(\"dataset/csv/dev.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "439149d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>line_number</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>total_lines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24464531</td>\n",
       "      <td>0</td>\n",
       "      <td>OBJECTIVE</td>\n",
       "      <td>To investigate the efficacy of 6 weeks of dail...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24464531</td>\n",
       "      <td>1</td>\n",
       "      <td>METHODS</td>\n",
       "      <td>A total of 125 patients with primary knee OA w...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24464531</td>\n",
       "      <td>2</td>\n",
       "      <td>METHODS</td>\n",
       "      <td>Outcome measures included pain reduction and i...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24464531</td>\n",
       "      <td>3</td>\n",
       "      <td>METHODS</td>\n",
       "      <td>Pain was assessed using the visual analog pain...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24464531</td>\n",
       "      <td>4</td>\n",
       "      <td>METHODS</td>\n",
       "      <td>Secondary outcome measures included the Wester...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180035</th>\n",
       "      <td>24464531</td>\n",
       "      <td>7</td>\n",
       "      <td>RESULTS</td>\n",
       "      <td>For the absolute change in percent atheroma vo...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180036</th>\n",
       "      <td>24464531</td>\n",
       "      <td>8</td>\n",
       "      <td>RESULTS</td>\n",
       "      <td>For PAV , a significantly greater percentage o...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180037</th>\n",
       "      <td>24464531</td>\n",
       "      <td>9</td>\n",
       "      <td>RESULTS</td>\n",
       "      <td>Both strategies had acceptable side effect pro...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180038</th>\n",
       "      <td>24464531</td>\n",
       "      <td>10</td>\n",
       "      <td>CONCLUSIONS</td>\n",
       "      <td>Compared with standard statin monotherapy , th...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180039</th>\n",
       "      <td>24464531</td>\n",
       "      <td>11</td>\n",
       "      <td>CONCLUSIONS</td>\n",
       "      <td>( Plaque Regression With Cholesterol Absorptio...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180040 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID  line_number discourse_type  \\\n",
       "0       24464531            0      OBJECTIVE   \n",
       "1       24464531            1        METHODS   \n",
       "2       24464531            2        METHODS   \n",
       "3       24464531            3        METHODS   \n",
       "4       24464531            4        METHODS   \n",
       "...          ...          ...            ...   \n",
       "180035  24464531            7        RESULTS   \n",
       "180036  24464531            8        RESULTS   \n",
       "180037  24464531            9        RESULTS   \n",
       "180038  24464531           10    CONCLUSIONS   \n",
       "180039  24464531           11    CONCLUSIONS   \n",
       "\n",
       "                                           discourse_text  total_lines  \n",
       "0       To investigate the efficacy of 6 weeks of dail...           12  \n",
       "1       A total of 125 patients with primary knee OA w...           12  \n",
       "2       Outcome measures included pain reduction and i...           12  \n",
       "3       Pain was assessed using the visual analog pain...           12  \n",
       "4       Secondary outcome measures included the Wester...           12  \n",
       "...                                                   ...          ...  \n",
       "180035  For the absolute change in percent atheroma vo...           12  \n",
       "180036  For PAV , a significantly greater percentage o...           12  \n",
       "180037  Both strategies had acceptable side effect pro...           12  \n",
       "180038  Compared with standard statin monotherapy , th...           12  \n",
       "180039  ( Plaque Regression With Cholesterol Absorptio...           12  \n",
       "\n",
       "[180040 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b331a4b2",
   "metadata": {},
   "source": [
    "Turn into text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6caad89",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = train_data[\"discourse_text\"]\n",
    "test_sentences = test_data[\"discourse_text\"]\n",
    "val_sentences = val_data[\"discourse_text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbaf86bb",
   "metadata": {},
   "source": [
    "## Create text vectorizer layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3f7292",
   "metadata": {},
   "source": [
    "### turn vocab into tokenaization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f771396",
   "metadata": {},
   "source": [
    "See how many words are in our vocab\n",
    "\n",
    "( taken from table 2 in: https://arxiv.org/pdf/1710.06071/pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a28d244f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tokens = 68000  # the amount of words in dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ceb6d63",
   "metadata": {},
   "source": [
    "Create text vectorizer\n",
    "\n",
    "Plese refer the output_sequence_length in https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/09_SkimLit_nlp_milestone_project_2.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61898324",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "text_vectorizer = TextVectorization(max_tokens = max_tokens\n",
    "                                   , output_sequence_length = 55) # this is kind of magic number. See the github later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75261e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorizer.adapt(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0b33505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:\n",
      "The primary end point of IS/MaR was not significantly reduced .\n",
      "\n",
      "Length of text: 63\n",
      "\n",
      "Vectorized text: [[    2    57   208   350     4 34919    10    31    41   200     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0]]\n"
     ]
    }
   ],
   "source": [
    "# Test our text vectorizer on randome sentences\n",
    "import random\n",
    "target_sentence = random.choice(train_sentences)\n",
    "print(f\"Text:\\n{target_sentence}\")\n",
    "print(f\"\\nLength of text: {len(target_sentence)}\")\n",
    "print(f\"\\nVectorized text: {text_vectorizer([target_sentence])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8bd52ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in vocab: 68000\n",
      "Most common words in the vocab: ['', '[UNK]', 'the', 'and', 'of']\n",
      "Least common words in the vocab: ['httpsuploaduminacjpcgiopenbinctrctrcgifunctionbrowsactionbrowstypesummaryrecptnor000008238languagee', 'httpsregisterclinicaltrialsgov', 'httpsmartmicrosurgerycom', 'httpseudractemaeuropaeuindexhtml', 'httpseudractemaeuropaeu']\n"
     ]
    }
   ],
   "source": [
    "# How many words in our training vocablary\n",
    "\n",
    "rct_20k_text_vocab = text_vectorizer.get_vocabulary()\n",
    "print(f\"Number of words in vocab: {len(rct_20k_text_vocab)}\")\n",
    "print(f\"Most common words in the vocab: {rct_20k_text_vocab[:5]}\")\n",
    "print(f\"Least common words in the vocab: {rct_20k_text_vocab[-5:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e0cf15",
   "metadata": {},
   "source": [
    "Get config of our text vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e14b3a8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'text_vectorization',\n",
       " 'trainable': True,\n",
       " 'batch_input_shape': (None, None),\n",
       " 'dtype': 'string',\n",
       " 'max_tokens': 68000,\n",
       " 'standardize': 'lower_and_strip_punctuation',\n",
       " 'split': 'whitespace',\n",
       " 'ngrams': None,\n",
       " 'output_mode': 'int',\n",
       " 'output_sequence_length': 55,\n",
       " 'pad_to_max_tokens': False,\n",
       " 'sparse': False,\n",
       " 'ragged': False,\n",
       " 'vocabulary': None,\n",
       " 'idf_weights': None}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vectorizer.get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca83dc6",
   "metadata": {},
   "source": [
    "### turn vocab numbers into embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "13f560b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = layers.Embedding(input_dim = 68000 # the size of input shape: the size of vocab in our data\n",
    "                            ,output_dim = 128 # the output shape\n",
    "                            ,mask_zero = True # use masking to handle variable\n",
    "                            ,name=\"tokes_embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c13e46df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: After RP , 388 patients with pT3 pN0 prostate cancer ( PCa ) were randomized to WS or three-dimensional conformal ART with 60 Gy .\n",
      "tf.Tensor(\n",
      "[[[-0.00244201 -0.01134448  0.02494658 ...  0.04407774 -0.02176236\n",
      "   -0.03933561]\n",
      "  [-0.03842627 -0.02807379 -0.03776301 ... -0.00694171  0.01628477\n",
      "    0.02554039]\n",
      "  [-0.03869795  0.02921561  0.01425767 ...  0.04785431 -0.03675254\n",
      "    0.04732194]\n",
      "  ...\n",
      "  [ 0.01163961  0.01285144 -0.01969146 ... -0.01965425  0.0349629\n",
      "   -0.02381796]\n",
      "  [ 0.01163961  0.01285144 -0.01969146 ... -0.01965425  0.0349629\n",
      "   -0.02381796]\n",
      "  [ 0.01163961  0.01285144 -0.01969146 ... -0.01965425  0.0349629\n",
      "   -0.02381796]]], shape=(1, 55, 128), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Show example embedding\n",
    "target_original_text = random.choice(train_sentences)\n",
    "target_vec_text = text_vectorizer([target_original_text])\n",
    "print(f\"Original text: {target_original_text}\")\n",
    "print(embedding(target_vec_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "90e13916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'tokes_embedding',\n",
       " 'trainable': True,\n",
       " 'batch_input_shape': (None, None),\n",
       " 'dtype': 'float32',\n",
       " 'input_dim': 68000,\n",
       " 'output_dim': 128,\n",
       " 'embeddings_initializer': {'class_name': 'RandomUniform',\n",
       "  'config': {'minval': -0.05, 'maxval': 0.05, 'seed': None}},\n",
       " 'embeddings_regularizer': None,\n",
       " 'activity_regularizer': None,\n",
       " 'embeddings_constraint': None,\n",
       " 'mask_zero': True,\n",
       " 'input_length': None}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67380011",
   "metadata": {},
   "source": [
    "## Create Simple Conv1D model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e063dc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = layers.Input(shape = (1,), dtype = tf.string)\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "x = layers.Conv1D(filters = 64, kernel_size = 5, activation = \"relu\", padding = \"valid\")(x)\n",
    "x = layers.GlobalMaxPool1D()(x)\n",
    "outputs = layers.Dense(1, activation = \"sigmoid\")(x)\n",
    "model1_Conv1D = tf.keras.Model(inputs, outputs, name=\"model1_Conv1D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3e71e1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model1_Conv1D\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization (TextVec  (None, 55)               0         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " tokes_embedding (Embedding)  (None, 55, 128)          8704000   \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 51, 64)            41024     \n",
      "                                                                 \n",
      " global_max_pooling1d_1 (Glo  (None, 64)               0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,745,089\n",
      "Trainable params: 8,745,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1_Conv1D.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
