{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "697c3b95",
   "metadata": {},
   "source": [
    "# Use Pretrained Feature Extraction model from Tensorflow Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c46d29",
   "metadata": {},
   "source": [
    "Import liblaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c390ad71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_hub as hub\n",
    "import random\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from helper_function import calculate_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6e57d6",
   "metadata": {},
   "source": [
    "## read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2e429346",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./dataset/csv/train.csv')\n",
    "test_data = pd.read_csv('./dataset/csv/test.csv')\n",
    "val_data = pd.read_csv('./dataset/csv/dev.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b115bf71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'line_number', 'discourse_type', 'discourse_text', 'total_lines'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(train_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "51755cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = train_data[\"discourse_text\"]\n",
    "test_sentences = test_data[\"discourse_text\"]\n",
    "val_sentences = val_data[\"discourse_text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ae5ead",
   "metadata": {},
   "source": [
    "## Get model from tensorflow hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "63625f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_hub_embedding_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
    "                                       trainable = False,\n",
    "                                       name = \"universal_sentence_encoder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033df77a",
   "metadata": {},
   "source": [
    "Test pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2e6cc3ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence :The sum of both the complete ( proctitis symptoms plus quality of life ) and partial ( proctitis symptoms ) scores of the EORTC QLQ-PRT23 ( European Organization for Research and Treatment of Cancer Quality of Life Module for Proctitis-23 items ) questionnaire were the main endpoints .\n",
      "embeddded tensor : [ 0.00856564 -0.07985796  0.02184752  0.06190689  0.03349479 -0.08490837\n",
      " -0.03335121 -0.01556801 -0.0488999  -0.04151303  0.08705017 -0.01882007\n",
      "  0.0509972  -0.007896    0.01913275 -0.0051905  -0.08388961  0.03110675\n",
      "  0.07423677  0.04787413 -0.00290271  0.05419457 -0.01135959  0.01923758\n",
      "  0.02862718 -0.02773495 -0.0398179   0.00015636  0.01413737  0.02854043]\n",
      "Length of output: 512\n"
     ]
    }
   ],
   "source": [
    "random_choice_sentence = random.choice(train_sentences)\n",
    "embedded_random_sentence = tf_hub_embedding_layer([random_choice_sentence])\n",
    "\n",
    "print(f\"Original sentence :{random_choice_sentence}\")\n",
    "print(f\"embeddded tensor : {embedded_random_sentence[0][:30]}\")\n",
    "print(f\"Length of output: {len(embedded_random_sentence[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4750aec",
   "metadata": {},
   "source": [
    "## Build and fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5e7f8456",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = layers.Input(shape=[], dtype=tf.string)\n",
    "embedding = tf_hub_embedding_layer(inputs)\n",
    "x = layers.Dense(128, activation = tf.keras.activations.relu)(embedding)\n",
    "outputs = layers.Dense(5, activation = tf.keras.activations.softmax)(x)\n",
    "\n",
    "model2 = tf.keras.Model(inputs = inputs,\n",
    "                       outputs = outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e2ebb56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None,)]                 0         \n",
      "                                                                 \n",
      " universal_sentence_encoder   (None, 512)              256797824 \n",
      " (KerasLayer)                                                    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               65664     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256,864,133\n",
      "Trainable params: 66,309\n",
      "Non-trainable params: 256,797,824\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f7627f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "\n",
    "model2.compile(loss = tf.keras.metrics.categorical_crossentropy,\n",
    "              optimizer = tf.keras.optimizers.Adam(),\n",
    "              metrics = [\"accuracy\"] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64d529d",
   "metadata": {},
   "source": [
    "## Create train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "711f3412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create one-hot encoded values\n",
    "\n",
    "one_hot_encoder = OneHotEncoder( sparse = False )\n",
    "train_lables_one_hot = one_hot_encoder.fit_transform(train_data[\"discourse_type\"].to_numpy().reshape(-1,1))\n",
    "test_lables_one_hot = one_hot_encoder.fit_transform(test_data[\"discourse_type\"].to_numpy().reshape(-1,1))\n",
    "val_lables_one_hot = one_hot_encoder.fit_transform(val_data[\"discourse_type\"].to_numpy().reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "05745fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn data into Tensorflow datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_sentences, train_lables_one_hot))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_sentences, test_lables_one_hot))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_sentences, val_lables_one_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2a9e029a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn TensoflowSliceDataset into prefetch batches\n",
    "train_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "val_dataset = val_dataset.batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7959fc85",
   "metadata": {},
   "source": [
    "## Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e7506913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "562/562 [==============================] - 20s 23ms/step - loss: 0.8897 - accuracy: 0.6634 - val_loss: 0.7757 - val_accuracy: 0.6955\n",
      "Epoch 2/3\n",
      "562/562 [==============================] - 12s 21ms/step - loss: 0.7430 - accuracy: 0.7105 - val_loss: 0.7330 - val_accuracy: 0.7128\n",
      "Epoch 3/3\n",
      "562/562 [==============================] - 12s 21ms/step - loss: 0.7264 - accuracy: 0.7203 - val_loss: 0.7190 - val_accuracy: 0.7194\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x188be4e0310>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(train_dataset,\n",
    "           steps_per_epoch = int(0.1 * len(train_dataset)),\n",
    "           epochs = 3,\n",
    "           validation_data = val_dataset,\n",
    "           validation_steps = int(0.1 * len(val_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6b923605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 16s 17ms/step - loss: 0.7161 - accuracy: 0.7246\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7160554528236389, 0.7245796322822571]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe23105",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c7e0dcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_pred_probs = model2.predict(val_dataset)\n",
    "model2_pred = tf.argmax( model2_pred_probs, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6cc0f669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([0, 1, 3, ..., 4, 4, 2], dtype=int64)>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5d9c0bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "val_label_encoded = label_encoder.fit_transform(val_data[\"discourse_type\"].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ea3820d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 72.45796372302397,\n",
       " 'precision': 0.7253693680271917,\n",
       " 'recall': 0.7245796372302397,\n",
       " 'f1': 0.7220015062365588}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_results(y_true = val_label_encoded,\n",
    "                 y_pred = model2_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
